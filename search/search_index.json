{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Official English Documentation for PreImutils! \u00b6 PreImutils is a python library built to empower developers, reseachers and students to prepare and preprocessing image datasets for applications and systems with Deep Learning and Computer Vision capabilities using simple and few lines of code. This documentation is provided to provide detailed insight into all the classes and functions available in PreImutils, coupled with a number of code examples. The Official GitHub Repository of PreImutils is https://github.com/mrl-amrl/preimutils Easy to use: \u00b6 Why we need PreImutils? \u00b6 Everything that you need to preprocess your image dataset is here. One of the most important item for machine learning or CNN or other neural networks is preparing your dataset. Note It's easy to use: You can use both in terminal and code Python from preimutils import AMRLImageAug img_aug = AMRLImageAug ( json_path , xmls_dir , images_dir ) img_aug . auto_augmentation ( quantity , resized = True , width = 300 , height = 300 ) Bash JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ FUNCTION = auto_augmentation QUANTITY = 1000 # the amount of each object to create preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR --quantity $QUANTITY Somepoint The amount of your dataset is really important. Not very few that lose the accuracy not great number of that lose your time and cause to overfitting, more than 4000 image per object is enough that mostly. depend on how much your feature is hard. The amount of each object image is important if objects sample count not equal your neural network forget the lower object count for instance if you have 3 object each one should have 4000 sample. Don't forget to shuffle your dataset if you don't do that you never ever don't get good accuracy on all of your objects. If you want to detect your object from all angles don't forget to put sample from other angle Attention No : object Sample Count object 1 2000 object 2 1000 object 3 4000 Yes : object Sample Count object 1 3900 object 2 4100 object 3 4000 PreImutils help you to do these points in few line of code. How should I use the documentation? \u00b6 If you are getting started with the library, you should follow the documentation in order by pressing the \u201cNext\u201d button at the bottom-right of every page. You can also use the menu on the left to quickly skip over sections.","title":"Official English Documentation for PreImutils!"},{"location":"#official-english-documentation-for-preimutils","text":"PreImutils is a python library built to empower developers, reseachers and students to prepare and preprocessing image datasets for applications and systems with Deep Learning and Computer Vision capabilities using simple and few lines of code. This documentation is provided to provide detailed insight into all the classes and functions available in PreImutils, coupled with a number of code examples. The Official GitHub Repository of PreImutils is https://github.com/mrl-amrl/preimutils","title":"Official English Documentation for PreImutils!"},{"location":"#easy-to-use","text":"","title":"Easy to use:"},{"location":"#why-we-need-preimutils","text":"Everything that you need to preprocess your image dataset is here. One of the most important item for machine learning or CNN or other neural networks is preparing your dataset. Note It's easy to use: You can use both in terminal and code Python from preimutils import AMRLImageAug img_aug = AMRLImageAug ( json_path , xmls_dir , images_dir ) img_aug . auto_augmentation ( quantity , resized = True , width = 300 , height = 300 ) Bash JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ FUNCTION = auto_augmentation QUANTITY = 1000 # the amount of each object to create preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR --quantity $QUANTITY Somepoint The amount of your dataset is really important. Not very few that lose the accuracy not great number of that lose your time and cause to overfitting, more than 4000 image per object is enough that mostly. depend on how much your feature is hard. The amount of each object image is important if objects sample count not equal your neural network forget the lower object count for instance if you have 3 object each one should have 4000 sample. Don't forget to shuffle your dataset if you don't do that you never ever don't get good accuracy on all of your objects. If you want to detect your object from all angles don't forget to put sample from other angle Attention No : object Sample Count object 1 2000 object 2 1000 object 3 4000 Yes : object Sample Count object 1 3900 object 2 4100 object 3 4000 PreImutils help you to do these points in few line of code.","title":"Why we need PreImutils?"},{"location":"#how-should-i-use-the-documentation","text":"If you are getting started with the library, you should follow the documentation in order by pressing the \u201cNext\u201d button at the bottom-right of every page. You can also use the menu on the left to quickly skip over sections.","title":"How should I use the documentation?"},{"location":"coco/","text":"Work in Progress","title":"COCO dataset"},{"location":"installation/","text":"Build from source \u00b6 git clone https://github.com/mrl-amrl/preimutils.git cd preimutils sudo pip3 install -r requirements.txt Get from PyPI \u00b6 sudo pip3 install preimutils","title":"Installation"},{"location":"installation/#build-from-source","text":"git clone https://github.com/mrl-amrl/preimutils.git cd preimutils sudo pip3 install -r requirements.txt","title":"Build from source"},{"location":"installation/#get-from-pypi","text":"sudo pip3 install preimutils","title":"Get from PyPI"},{"location":"object-detection/","text":"Prepare Your dataset \u00b6 Warning When use PreImutils object detection please put your data in this pattern +dataset -label.json +images +annotations sample of label.json file { \"1\" : \"object1\" , \"2\" : \"object2\" , \"3\" : \"object3\" , \"4\" : \"object4\" , \"5\" : \"object5\" , \"6\" : \"object6\" , \"7\" : \"object7\" , \"8\" : \"object8\" , \"9\" : \"object9\" , \"10\" : \"object10\" , \"11\" : \"object11\" , \"12\" : \"object12\" , \"13\" : \"object13\" } Download dataset \u00b6 For downloading your dataset I suggest you to use google_images_download package easy to use pip install google_images_download Labeling \u00b6 For labeling (bounding box) I suggest you to use labelImg and suggest to label in PASCAL_VOC mode because you can easily work on in and convert to coco and YOLO. Convert to Yolo \u00b6 For converting to YOLO use convert2Yolo Rename image path in Annotations file \u00b6 When You move your dataset files from some place to another you need to change image path in the .xml file this function find the related image file in your image path and replace the annotation path after moving <annotation> <folder> voc2012 </folder> <filename> 000001 </filename> <path> ~/old_path/000001.jpg </path> <source> <database> Unknown </database> </source> <size> <width> 353 </width> <height> 500 </height> <depth> 3 </depth> </size> <segmented> 0 </segmented> <object> <name> sample_object </name> <pose> Unspecified </pose> <truncated> 0 </truncated> <difficult> 0 </difficult> <bndbox> <xmin> 129 </xmin> <ymin> 31 </ymin> <xmax> 298 </xmax> <ymax> 227 </ymax> </bndbox> </object> </annotation> How to use in code \u00b6 from preimutils.object_detection import xml_address_changer xml_address_changer ( xmls_dir , images_dir ) How to use terminal \u00b6 JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ FUNCTION = xml_address_changer preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR Checking for valid labels \u00b6 label_checker \u00b6 Imaging your labeling team label some wrong label on your picture you can find with this function and replace with the correct one with Replace label How to use in code \u00b6 from preimutils.object_detection import label_checker from preimutils.object_detection import LabelHandler label = LabelHandler ( json_path ) classes_array = label . json_label_array () # or you can Prepare it manually # if there were problem print the file and wrong label for and write the statistic of each label in another json file label_checker ( xmls_dir , classes_array ) replace_label ( xmls_dir , from_label , dst_label ) How to use terminal \u00b6 JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ FUNCTION = label_checker preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR Replace label \u00b6 Imaging your labeling team label some wrong label on your picture you can replace it with the currect one. for instance: instead of object some of label write object. How to use in code \u00b6 from preimutils.object_detection import replace_label , label_checker label = LabelHandler ( json_path ) classes_array = label . json_label_array () # or you can Prepare it manually # if there were problem print the file and wrong label for and write the statistic of each label in another json file label_checker ( xmls_dir , classes_array ) replace_label ( xmls_dir , from_label , dst_label ) How to use terminal \u00b6 JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ DST_LABEL = YOUR_CORRECT_LABEL SOURCE_LABEL = YOUR_WRONG_LABEL FUNCTION = replace_label preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --label $SOURCE_LABEL --dst_label $DST_LABEL Crop from point \u00b6 Some time you label your images but you need the pure images for instance for training haarcascade method with OpenCV or training simple convolutional neural network this function crop images with their bbox and separating to their related object name. How to use in code \u00b6 from preimutils.object_detection import cut_with_object_names if __name__ == \"__main__\" : cut_with_object_names ( images_dir , xmls_dir , dst_save , labels ) How to use terminal \u00b6 JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ DST_SAVE = ~/YOUR_DESTINATION_DIR/ FUNCTION = cut_with_object_names preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --dst_save $DST_SAVE --images_dir $IMAGES_DIR Separate with label \u00b6 Separate images and their related annotations files on their object name file after working on your separated dataset you can gather all of them together with gather_together(label_array, DATASET_PATH) after run +dataset -label.json +images +annotations +object +images +annotations +object2 +images +annotations +objectN +images +annotations How to use in code \u00b6 from preimutils.object_detection import separate_with_label , gather_together separate_with_label ( XML_PATH , IMAGE_PATH , label_array ) # after working on your separated dataset you can gather all of them together gather_together ( label_array , DATASET_PATH ) How to use terminal \u00b6 JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ FUNCTION = separate_with_label preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR Shuffle dataset images and annotations \u00b6 One of the easiest but the most important point for pretraining, if you don't shuffle your images and their annotation your neural network won't get accurate result. This function shuffling images and their related annotations and save in the destination directory How to use in code \u00b6 from preimutils.object_detection as shuffle_img_xml shuffle_img_xml ( XMLS_DIR , IMAGES_DIR , DST_PATH ) How to use shell \u00b6 JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ DST_SAVE = ~/YOUR_DESTINATION_DIR/ FUNCTION = shuffle_img_xml preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR --dst_save $DST_SAVE Image augmentation \u00b6 One of the most important item for machine learning, CNN or other neural networks is augmenting your dataset in different situations. I've used all the augmentations method and highly recommend you to use this package albumentations . Write a good wrapper for this package with the best filter of this package that calculate the number of each object and then augment all of them in amount that you want. How to use in code \u00b6 from preimutils.object_detection import AMRLImageAug img_aug = AMRLImageAug ( json_path , xmls_dir , images_dir ) img_aug . auto_augmentation ( quantity ) If you want to resize your images set resized param True and pass the width and height in parameters. Point As you know, if you use resize with other functions such as cv2.resized() your bounding box will be disarrange. from preimutils.object_detection import AMRLImageAug img_aug = AMRLImageAug ( json_path , xmls_dir , images_dir ) img_aug . auto_augmentation ( quantity , resized = True , width = 300 , height = 300 ) How to use terminal \u00b6 Without resize JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ FUNCTION = auto_augmentation QUANTITY = 1000 # the amount of each object to create preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR --quantity $QUANTITY Resize JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ FUNCTION = auto_augmentation QUANTITY = 1000 # the amount of each object to create RESIZE = True # If you want to resize You should set WIDTH and WIDTH param WIDTH = 300 HEIGHT = 300 preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR --quantity $QUANTITY --resize $RESIZE --width $WIDTH --height $HEIGHT Train validate separator \u00b6 We provide tool for separating your images for train and validation dataset with their related annotations. How to use in code \u00b6 from preimutils.object_detection import separate_test_val separate_test_val ( IMAGES_DIR , XMLS_DIR , DST_VALIDATION_PATH , DST_TRAIN_PATH , validation_percentage = 0.3 ) How to use terminal \u00b6 JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ DATASET_PATH = ~/DATASET_PATH/ VALIDATION_PERSENT = 0 .3 FUNCTION = separate_test_val preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR --dataset_dir $DATASET_PATH --validation_persent $VALIDATION_PERSENT XML to csv converting \u00b6 This function convert pascal-voc format to csv How to use terminal \u00b6 JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ DST_SAVE = ~/YOUR_DESTINATION_DIR/ VALIDATION_PERSENT = 0 .3 FUNCTION = xml_to_csv preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --dst_save $DST_SAVE Statistics of your Dataset labels \u00b6 Get statistics of dataset with their labels with their xmls and images files path return dict { \"label1\" : { \"count\" : 0 , \"xmls_paths\" :[], \"images_paths\" :[], }, \"labelN\" : { \"count\" : 0 , \"xmls_paths\" :[], \"images_paths\" :[], }, } How to use in code \u00b6 from preimutils.object_detection import export_path_count_for_each_label export_path_count_for_each_label ( xmls_dir , images_dir , labels )","title":"Object Detection Dataset"},{"location":"object-detection/#prepare-your-dataset","text":"Warning When use PreImutils object detection please put your data in this pattern +dataset -label.json +images +annotations sample of label.json file { \"1\" : \"object1\" , \"2\" : \"object2\" , \"3\" : \"object3\" , \"4\" : \"object4\" , \"5\" : \"object5\" , \"6\" : \"object6\" , \"7\" : \"object7\" , \"8\" : \"object8\" , \"9\" : \"object9\" , \"10\" : \"object10\" , \"11\" : \"object11\" , \"12\" : \"object12\" , \"13\" : \"object13\" }","title":"Prepare Your dataset"},{"location":"object-detection/#download-dataset","text":"For downloading your dataset I suggest you to use google_images_download package easy to use pip install google_images_download","title":"Download dataset"},{"location":"object-detection/#labeling","text":"For labeling (bounding box) I suggest you to use labelImg and suggest to label in PASCAL_VOC mode because you can easily work on in and convert to coco and YOLO.","title":"Labeling"},{"location":"object-detection/#convert-to-yolo","text":"For converting to YOLO use convert2Yolo","title":"Convert to Yolo"},{"location":"object-detection/#rename-image-path-in-annotations-file","text":"When You move your dataset files from some place to another you need to change image path in the .xml file this function find the related image file in your image path and replace the annotation path after moving <annotation> <folder> voc2012 </folder> <filename> 000001 </filename> <path> ~/old_path/000001.jpg </path> <source> <database> Unknown </database> </source> <size> <width> 353 </width> <height> 500 </height> <depth> 3 </depth> </size> <segmented> 0 </segmented> <object> <name> sample_object </name> <pose> Unspecified </pose> <truncated> 0 </truncated> <difficult> 0 </difficult> <bndbox> <xmin> 129 </xmin> <ymin> 31 </ymin> <xmax> 298 </xmax> <ymax> 227 </ymax> </bndbox> </object> </annotation>","title":"Rename image path in Annotations file"},{"location":"object-detection/#how-to-use-in-code","text":"from preimutils.object_detection import xml_address_changer xml_address_changer ( xmls_dir , images_dir )","title":"How to use in code"},{"location":"object-detection/#how-to-use-terminal","text":"JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ FUNCTION = xml_address_changer preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR","title":"How to use terminal"},{"location":"object-detection/#checking-for-valid-labels","text":"","title":"Checking for valid labels"},{"location":"object-detection/#label_checker","text":"Imaging your labeling team label some wrong label on your picture you can find with this function and replace with the correct one with Replace label","title":"label_checker"},{"location":"object-detection/#how-to-use-in-code_1","text":"from preimutils.object_detection import label_checker from preimutils.object_detection import LabelHandler label = LabelHandler ( json_path ) classes_array = label . json_label_array () # or you can Prepare it manually # if there were problem print the file and wrong label for and write the statistic of each label in another json file label_checker ( xmls_dir , classes_array ) replace_label ( xmls_dir , from_label , dst_label )","title":"How to use in code"},{"location":"object-detection/#how-to-use-terminal_1","text":"JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ FUNCTION = label_checker preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR","title":"How to use terminal"},{"location":"object-detection/#replace-label","text":"Imaging your labeling team label some wrong label on your picture you can replace it with the currect one. for instance: instead of object some of label write object.","title":"Replace label"},{"location":"object-detection/#how-to-use-in-code_2","text":"from preimutils.object_detection import replace_label , label_checker label = LabelHandler ( json_path ) classes_array = label . json_label_array () # or you can Prepare it manually # if there were problem print the file and wrong label for and write the statistic of each label in another json file label_checker ( xmls_dir , classes_array ) replace_label ( xmls_dir , from_label , dst_label )","title":"How to use in code"},{"location":"object-detection/#how-to-use-terminal_2","text":"JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ DST_LABEL = YOUR_CORRECT_LABEL SOURCE_LABEL = YOUR_WRONG_LABEL FUNCTION = replace_label preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --label $SOURCE_LABEL --dst_label $DST_LABEL","title":"How to use terminal"},{"location":"object-detection/#crop-from-point","text":"Some time you label your images but you need the pure images for instance for training haarcascade method with OpenCV or training simple convolutional neural network this function crop images with their bbox and separating to their related object name.","title":"Crop from point"},{"location":"object-detection/#how-to-use-in-code_3","text":"from preimutils.object_detection import cut_with_object_names if __name__ == \"__main__\" : cut_with_object_names ( images_dir , xmls_dir , dst_save , labels )","title":"How to use in code"},{"location":"object-detection/#how-to-use-terminal_3","text":"JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ DST_SAVE = ~/YOUR_DESTINATION_DIR/ FUNCTION = cut_with_object_names preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --dst_save $DST_SAVE --images_dir $IMAGES_DIR","title":"How to use terminal"},{"location":"object-detection/#separate-with-label","text":"Separate images and their related annotations files on their object name file after working on your separated dataset you can gather all of them together with gather_together(label_array, DATASET_PATH) after run +dataset -label.json +images +annotations +object +images +annotations +object2 +images +annotations +objectN +images +annotations","title":"Separate with label"},{"location":"object-detection/#how-to-use-in-code_4","text":"from preimutils.object_detection import separate_with_label , gather_together separate_with_label ( XML_PATH , IMAGE_PATH , label_array ) # after working on your separated dataset you can gather all of them together gather_together ( label_array , DATASET_PATH )","title":"How to use in code"},{"location":"object-detection/#how-to-use-terminal_4","text":"JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ FUNCTION = separate_with_label preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR","title":"How to use terminal"},{"location":"object-detection/#shuffle-dataset-images-and-annotations","text":"One of the easiest but the most important point for pretraining, if you don't shuffle your images and their annotation your neural network won't get accurate result. This function shuffling images and their related annotations and save in the destination directory","title":"Shuffle dataset images and annotations"},{"location":"object-detection/#how-to-use-in-code_5","text":"from preimutils.object_detection as shuffle_img_xml shuffle_img_xml ( XMLS_DIR , IMAGES_DIR , DST_PATH )","title":"How to use in code"},{"location":"object-detection/#how-to-use-shell","text":"JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ DST_SAVE = ~/YOUR_DESTINATION_DIR/ FUNCTION = shuffle_img_xml preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR --dst_save $DST_SAVE","title":"How to use shell"},{"location":"object-detection/#image-augmentation","text":"One of the most important item for machine learning, CNN or other neural networks is augmenting your dataset in different situations. I've used all the augmentations method and highly recommend you to use this package albumentations . Write a good wrapper for this package with the best filter of this package that calculate the number of each object and then augment all of them in amount that you want.","title":"Image augmentation"},{"location":"object-detection/#how-to-use-in-code_6","text":"from preimutils.object_detection import AMRLImageAug img_aug = AMRLImageAug ( json_path , xmls_dir , images_dir ) img_aug . auto_augmentation ( quantity ) If you want to resize your images set resized param True and pass the width and height in parameters. Point As you know, if you use resize with other functions such as cv2.resized() your bounding box will be disarrange. from preimutils.object_detection import AMRLImageAug img_aug = AMRLImageAug ( json_path , xmls_dir , images_dir ) img_aug . auto_augmentation ( quantity , resized = True , width = 300 , height = 300 )","title":"How to use in code"},{"location":"object-detection/#how-to-use-terminal_5","text":"Without resize JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ FUNCTION = auto_augmentation QUANTITY = 1000 # the amount of each object to create preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR --quantity $QUANTITY Resize JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ FUNCTION = auto_augmentation QUANTITY = 1000 # the amount of each object to create RESIZE = True # If you want to resize You should set WIDTH and WIDTH param WIDTH = 300 HEIGHT = 300 preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR --quantity $QUANTITY --resize $RESIZE --width $WIDTH --height $HEIGHT","title":"How to use terminal"},{"location":"object-detection/#train-validate-separator","text":"We provide tool for separating your images for train and validation dataset with their related annotations.","title":"Train validate separator"},{"location":"object-detection/#how-to-use-in-code_7","text":"from preimutils.object_detection import separate_test_val separate_test_val ( IMAGES_DIR , XMLS_DIR , DST_VALIDATION_PATH , DST_TRAIN_PATH , validation_percentage = 0.3 )","title":"How to use in code"},{"location":"object-detection/#how-to-use-terminal_6","text":"JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ IMAGES_DIR = ~/YOUR_IMAGES_DIR/ DATASET_PATH = ~/DATASET_PATH/ VALIDATION_PERSENT = 0 .3 FUNCTION = separate_test_val preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --images_dir $IMAGES_DIR --dataset_dir $DATASET_PATH --validation_persent $VALIDATION_PERSENT","title":"How to use terminal"},{"location":"object-detection/#xml-to-csv-converting","text":"This function convert pascal-voc format to csv","title":"XML to csv converting"},{"location":"object-detection/#how-to-use-terminal_7","text":"JSON_PATH = ~/YOUR_JSON_PATH/label.json XMLS_DIR = ~/YOUR_ANNOTATION_DIR/ DST_SAVE = ~/YOUR_DESTINATION_DIR/ VALIDATION_PERSENT = 0 .3 FUNCTION = xml_to_csv preimutils --function $FUNCTION --label_json_path $JSON_PATH --xmls_dir $XMLS_DIR --dst_save $DST_SAVE","title":"How to use terminal"},{"location":"object-detection/#statistics-of-your-dataset-labels","text":"Get statistics of dataset with their labels with their xmls and images files path return dict { \"label1\" : { \"count\" : 0 , \"xmls_paths\" :[], \"images_paths\" :[], }, \"labelN\" : { \"count\" : 0 , \"xmls_paths\" :[], \"images_paths\" :[], }, }","title":"Statistics of your Dataset labels"},{"location":"object-detection/#how-to-use-in-code_8","text":"from preimutils.object_detection import export_path_count_for_each_label export_path_count_for_each_label ( xmls_dir , images_dir , labels )","title":"How to use in code"},{"location":"segmentation/","text":"What dataset do you have ? \u00b6 If you using voc format you should see VOC dataset If you using voc format you should see COCO dataset","title":"Segmentation Dataset"},{"location":"segmentation/#what-dataset-do-you-have","text":"If you using voc format you should see VOC dataset If you using voc format you should see COCO dataset","title":"What dataset do you have ?"},{"location":"voc/","text":"Warning When use PreImutils VOC segmentation it's easier to put your data in below pattern . \u2514\u2500\u2500 ${ YOUR_DATASET_DIR } \u251c\u2500\u2500 ImageSets \u2502 \u2514\u2500\u2500 Segmentation \u2502 \u2514\u2500\u2500 train.txt \u2502 \u2514\u2500\u2500 val.txt \u2502 \u2514\u2500\u2500 trainval.txt \u251c\u2500\u2500 JPEGImages \u251c\u2500\u2500 SegmentationClass \u251c\u2500\u2500 SegmentationClassRaw \u251c\u2500\u2500 SegmentationObject \u2514\u2500\u2500 labelmap.txt If you have custom dataset just use below method from preimutils.segmentations.voc import utils utils . custom_to_voc ( 'YOUR_MASKS_DIR' , 'YOUR_IMAGES_DIR' , 'TARGET_TO_SAVE_VOC_DS' ) preimutils.segmentation.voc.utils \u00b6 Modules \u00b6 preimutils.segmentations.voc. utils custom_to_voc ( masks_dir , images_dir , target_dir ) Convert your custom dataset to normal voc format Args: masks_dir (str): your masks path. images_dir (str): your images path. Returns: (list) : unique colors from your masks decode_segmap ( label_mask , class_color , plot=False ) Decode segmentation class labels into a color image Args: label_mask (np.ndarray): an (M,N) array of integer values denoting the class label at each spatial location. plot (bool, optional): whether to show the resulting color image in a figure. Returns: (np.ndarray, optional): the resulting decoded color image. encode_segmap ( mask , class_color ) Encode segmentation label images as pascal classes Args: mask (np.ndarray): raw segmentation label image of dimension (M, N, 3), in which the Pascal classes are encoded as colours. class_color(list): class colors Returns: (np.ndarray): class map with dimensions (M,N), where the value at a given location is the integer denoting the class index. export_path_count_for_each_label ( color_label , images_dir , masks_dir ) Get statistics of dataset with their labels with their mask and images files path Args: xmls_dir : all xmls file directory . images_dir : your images directory . color_label :[( r , g , b ): object1 ,( r , g , b ): 'object2' ,...,( r , g , b ): 'objectN' ] Return: dict{ label1: { count: masks_paths:[] images_paths:[] }, ..., labelN: { count: masks_paths:[] images_paths:[] } } find_image_from_mask ( mask , images_dir ) Export image path from the mask file if your image and mask names are same Args: mask : single mask . png file path . images_dir : your images path . Returns: image path : path of the input mask -> string. find_maxmin_size_images ( images_dir ) Export the maximum and minimum size of the dataset images Args: images_dir : your images path . Returns: image path : path of the input mask -> string. unique_label_from_masks ( masks_dir ) get the unique colors(classes) from your masks Args: masks_dir:(str) your masks path. Returns: unique_colors : unique colors from your masks -> list . utils preimutils.segmentation.voc.Dataset \u00b6 Class \u00b6 class preimutils.segmentations.voc. Dataset ( dataset_dir ) Get dataset voc paths directly and some methods for work with it. \u251c\u2500\u2500 ImageSets \u2502 \u2514\u2500\u2500 Segmentation \u251c\u2500\u2500 JPEGImages \u251c\u2500\u2500 SegmentationClass \u251c\u2500\u2500 SegmentationClassRaw \u2514\u2500\u2500 SegmentationObject Attributes: masks_dir : SegmentationClass directory path images_dir : JPEGImages directory paths . segmentations_object_dir : SegmentationObject directory path label_map_path = labelmap . txt path check_valid_dataset ( self ) Check for all masks images if there isn't related mask image print the work image path If image not exist raise ValueError Args: None ValueError : if image that you want not exists Returns: None seprate_dataset ( self , shuffle=False , valid_persent=0.25 , test_persent=None , save=True ) Seprate dataset to train.txt,trainval.txt,val.txt Args: valid_persentage:(float), should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the validation split. If None,it will be set to 0.25. test_persentage: (float), should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If None, that means you don't have test dataset just have train validation. save :(bool), If True dataset save train.txt, trainval.txt, val.txt , if test_present exist test.txt Returns: None preimutils.segmentation.voc.LabelMap \u00b6 Class \u00b6 class preimutils.segmentations.voc. LabelMap ( label_map_path ) A class on to work and handel labelmap.txt classes Attributes: None Args: label_map_path (: obj : str ): you should have a txt file like this object1 : 0 , 0 , 0 :: object2 : 128 , 0 , 0 :: object3 : 0 , 128 , 0 :: objectN : 128 , 128 , 0 :: masks_dir ( str ): annotations files paths . images_dir ( str ) : images files paths . color_label ( self ) Export color_label dict Args: None Returns: a dict of label:color {(r,g,b):label1,(r,g,b):labelN} color_list ( self ) Export color_list in their saving order Args: None Returns: list of colors {(r,g,b),(rN,gN,bN)} label_color ( self ) Export label_color dict Args: None Returns: a dict of label:color {label1:(r,g,b),labelN:(r,g,b)} preimutils.segmentation.voc.SegmentationAug \u00b6 class preimutils.segmentations.voc. SegmentationAug ( label_map_path , masks_dir , images_dir ) A wrapper class on albumentations package to work on voc segmentation format easily Attributes: mask_dir : masks files paths . images_dir : images files paths . Args: label_map_path (: obj : str ): you should have a txt file like this object1 : 0 , 0 , 0 :: object2 : 128 , 0 , 0 :: object3 : 0 , 128 , 0 :: object4 : 128 , 128 , 0 :: object5 : 0 , 0 , 128 :: objectN : 128 , 0 , 128 :: masks_dir ( str ): annotations files paths . images_dir ( str ) : images files paths . augment_image ( self , mask_path , quantity , resize=False , width=0 , height=0 ) augmentation for one picture depend on quantity that you get for it if your image and mask names are same save your aug image in your dataset path with the following pattern aug_{counter}.jpg Args: mask_path : single mask file path . quantity : quantity for your image to augment resize :( bool : optional )-> defult False ... resize your augmented images width :( int : optional ) width for resized ... if resize True you should use this arg height :( int : optional ) height for resized ... if resize True you should use this arg Returns: No return auto_augmentation ( self , count_of_each ) auto augmentation for each picture depend on statistic of the object exist in your dataset if your image and mask names are same save your aug image in your dataset path with the following pattern aug_{counter}.jpg Args: count_of_each(int): How much of each label you want to have ! Returns: No return encode_mask_dataset ( self , class_color ) encode color map dataset masks to 1 channel mask used for most semantic segmentation models save your encoded mask in your YOUR_MASK_PATH/pre_encoded Args: class_color(int): [(r,g,b),(r,g,b),(r,g,b),...] Returns: No return","title":"VOC dataset"},{"location":"voc/#preimutilssegmentationvocutils","text":"","title":"preimutils.segmentation.voc.utils"},{"location":"voc/#modules","text":"preimutils.segmentations.voc. utils custom_to_voc ( masks_dir , images_dir , target_dir ) Convert your custom dataset to normal voc format Args: masks_dir (str): your masks path. images_dir (str): your images path. Returns: (list) : unique colors from your masks decode_segmap ( label_mask , class_color , plot=False ) Decode segmentation class labels into a color image Args: label_mask (np.ndarray): an (M,N) array of integer values denoting the class label at each spatial location. plot (bool, optional): whether to show the resulting color image in a figure. Returns: (np.ndarray, optional): the resulting decoded color image. encode_segmap ( mask , class_color ) Encode segmentation label images as pascal classes Args: mask (np.ndarray): raw segmentation label image of dimension (M, N, 3), in which the Pascal classes are encoded as colours. class_color(list): class colors Returns: (np.ndarray): class map with dimensions (M,N), where the value at a given location is the integer denoting the class index. export_path_count_for_each_label ( color_label , images_dir , masks_dir ) Get statistics of dataset with their labels with their mask and images files path Args: xmls_dir : all xmls file directory . images_dir : your images directory . color_label :[( r , g , b ): object1 ,( r , g , b ): 'object2' ,...,( r , g , b ): 'objectN' ] Return: dict{ label1: { count: masks_paths:[] images_paths:[] }, ..., labelN: { count: masks_paths:[] images_paths:[] } } find_image_from_mask ( mask , images_dir ) Export image path from the mask file if your image and mask names are same Args: mask : single mask . png file path . images_dir : your images path . Returns: image path : path of the input mask -> string. find_maxmin_size_images ( images_dir ) Export the maximum and minimum size of the dataset images Args: images_dir : your images path . Returns: image path : path of the input mask -> string. unique_label_from_masks ( masks_dir ) get the unique colors(classes) from your masks Args: masks_dir:(str) your masks path. Returns: unique_colors : unique colors from your masks -> list . utils","title":"Modules"},{"location":"voc/#preimutilssegmentationvocdataset","text":"","title":"preimutils.segmentation.voc.Dataset"},{"location":"voc/#class","text":"class preimutils.segmentations.voc. Dataset ( dataset_dir ) Get dataset voc paths directly and some methods for work with it. \u251c\u2500\u2500 ImageSets \u2502 \u2514\u2500\u2500 Segmentation \u251c\u2500\u2500 JPEGImages \u251c\u2500\u2500 SegmentationClass \u251c\u2500\u2500 SegmentationClassRaw \u2514\u2500\u2500 SegmentationObject Attributes: masks_dir : SegmentationClass directory path images_dir : JPEGImages directory paths . segmentations_object_dir : SegmentationObject directory path label_map_path = labelmap . txt path check_valid_dataset ( self ) Check for all masks images if there isn't related mask image print the work image path If image not exist raise ValueError Args: None ValueError : if image that you want not exists Returns: None seprate_dataset ( self , shuffle=False , valid_persent=0.25 , test_persent=None , save=True ) Seprate dataset to train.txt,trainval.txt,val.txt Args: valid_persentage:(float), should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the validation split. If None,it will be set to 0.25. test_persentage: (float), should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If None, that means you don't have test dataset just have train validation. save :(bool), If True dataset save train.txt, trainval.txt, val.txt , if test_present exist test.txt Returns: None","title":"Class"},{"location":"voc/#preimutilssegmentationvoclabelmap","text":"","title":"preimutils.segmentation.voc.LabelMap"},{"location":"voc/#class_1","text":"class preimutils.segmentations.voc. LabelMap ( label_map_path ) A class on to work and handel labelmap.txt classes Attributes: None Args: label_map_path (: obj : str ): you should have a txt file like this object1 : 0 , 0 , 0 :: object2 : 128 , 0 , 0 :: object3 : 0 , 128 , 0 :: objectN : 128 , 128 , 0 :: masks_dir ( str ): annotations files paths . images_dir ( str ) : images files paths . color_label ( self ) Export color_label dict Args: None Returns: a dict of label:color {(r,g,b):label1,(r,g,b):labelN} color_list ( self ) Export color_list in their saving order Args: None Returns: list of colors {(r,g,b),(rN,gN,bN)} label_color ( self ) Export label_color dict Args: None Returns: a dict of label:color {label1:(r,g,b),labelN:(r,g,b)}","title":"Class"},{"location":"voc/#preimutilssegmentationvocsegmentationaug","text":"class preimutils.segmentations.voc. SegmentationAug ( label_map_path , masks_dir , images_dir ) A wrapper class on albumentations package to work on voc segmentation format easily Attributes: mask_dir : masks files paths . images_dir : images files paths . Args: label_map_path (: obj : str ): you should have a txt file like this object1 : 0 , 0 , 0 :: object2 : 128 , 0 , 0 :: object3 : 0 , 128 , 0 :: object4 : 128 , 128 , 0 :: object5 : 0 , 0 , 128 :: objectN : 128 , 0 , 128 :: masks_dir ( str ): annotations files paths . images_dir ( str ) : images files paths . augment_image ( self , mask_path , quantity , resize=False , width=0 , height=0 ) augmentation for one picture depend on quantity that you get for it if your image and mask names are same save your aug image in your dataset path with the following pattern aug_{counter}.jpg Args: mask_path : single mask file path . quantity : quantity for your image to augment resize :( bool : optional )-> defult False ... resize your augmented images width :( int : optional ) width for resized ... if resize True you should use this arg height :( int : optional ) height for resized ... if resize True you should use this arg Returns: No return auto_augmentation ( self , count_of_each ) auto augmentation for each picture depend on statistic of the object exist in your dataset if your image and mask names are same save your aug image in your dataset path with the following pattern aug_{counter}.jpg Args: count_of_each(int): How much of each label you want to have ! Returns: No return encode_mask_dataset ( self , class_color ) encode color map dataset masks to 1 channel mask used for most semantic segmentation models save your encoded mask in your YOUR_MASK_PATH/pre_encoded Args: class_color(int): [(r,g,b),(r,g,b),(r,g,b),...] Returns: No return","title":"preimutils.segmentation.voc.SegmentationAug"}]}